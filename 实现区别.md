 H-Mem V1 vs 当前实现差异对比

  - 全局：核心架构依然是“冻结骨干+LoRA+SNMA+CHRC”，但现在对记忆更新、安全性和在线流程做了多处结构性改动（预校准、校正限幅、全局缩放、注意力版 CHRC 等）。

  LoRA 动态注入

  - 设计（H-memV1.md:115-228）：线性层 LoRA，支持批次/共享参数，动态注入/清理。
  - 现状 (adapter/module/lora.py):
      - 仍保留批次/共享 LoRA，但新增 Conv1d 与 Embedding 适配器，覆盖 Transformer 1×1 卷积和词表层 (LoRAConv1d/LoRAEmbedding，约行 153、220)。
      - 注入工具支持按模块名过滤目标层、冻结原权重、统计参数 (inject_lora_layers, get_lora_param_dims)，便于只改特定子模块。

  SNMA（短期神经记忆）

  - 惊奇度计算：与 V1 相同的自监督预测+运行统计思路 (H-memV1.md:246-333)，但现在可通过 momentum 入参调节平滑 (SurpriseCalculator 构造包含 momentum)。
  - 记忆更新 (adapter/module/neural_memory.py:132-201):
      - V1 直接用编码向量更新，未显式对齐维度 (H-memV1.md:333-469)；当前先投影到 memory_dim (encoding_proj)，解决编码维度与记忆维度不一致。
      - 更新强度改为 gate * (0.1 + 0.9*sigmoid(clamp(surprise,0,2)))，下限 0.1、上限平滑，避免惊奇度过大/过小导致的震荡；V1 是 gate * surprise，无截断与平滑。
      - 仍跟踪 age，但暂未参与权重衰减（V1 亦未使用）。
  - HyperNetwork (adapter/module/neural_memory.py:239-339, 300-306):
      - 结构与 V1 相同（共享编码 + 分层生成器，H-memV1.md:471-594），但现在对 B 生成器权重/偏置零初始化，输出尺度更小，降低初期扰动。
  - SNMA 封装 (adapter/module/neural_memory.py:367-449):
      - 返回值改为 (lora_params, memory_state[, diagnostics])，V1 的 diagnostics 形态不同；调用方需按新顺序解包。
      - reset 支持显式设备入参，便于分布式/AMP。

  CHRC 与错误记忆库

  - 记忆库 (util/error_bank.py:134-307): 与 V1 的多因素驱逐/时序衰减/Top-K 检索基本一致 (H-memV1.md:820-1100)，但参数化了 min_entries_for_retrieval (默认 10)。
  - 校正器 (util/error_bank.py:447-645):
      - 主干流程（编码 → 检索 → 聚合 → 质量估计 → 可选精炼 → 置信度门控）与 V1 保持一致 (H-memV1.md:1104-1325)。
      - 现实现将检索质量和“是否有有效检索”统一进 effective_confidence，输出细节键名与 V1 基本兼容。
  - 新增扩展：AdaptiveCHRC (注意力聚合 + 动态 top-k，util/error_bank.py:648-818)，V1 未设计该分支。

  HMem 主模块

  - LoRA 注入/冻结流程与 V1 一致 (H-memV1.md:1368-1586)，但有以下关键差异：
      - 校正限幅与全局缩放：CHRC 校正先 torch.clamp 到 [-chrc_max_correction, chrc_max_correction]，再乘全局缩放 chrc_global_scale (adapter/hmem.py:230-248)，V1 未做限
        幅/全局门。
      - 记忆库入库数据改为“适配前校正”的预测：现在存储 SNMA 适配后的 adapted_pred 而非 CHRC 校正后的输出 (adapter/hmem.py:257-261)，避免 CHRC 自反馈；V1 直接存
        corrected_pred (H-memV1.md:1587-1627)。
      - 冷启动处理：仍在无历史时跳过 CHRC，但同时返回零校正和零置信度 (adapter/hmem.py:216-225)，便于上层逻辑显式检测。
      - CHRC 可选全局启停/参数通过 args (use_chrc)，SNMA 可独立启停。

  在线训练与延迟更新

  - 设计时间线与两阶段策略保持一致 (H-memV1.md:1677-1900)，但实现上有多处加强：
      - 预测/校正存储：延迟更新缓冲区保存 pogt 与“未校正预测”（适配后输出），_process_delayed_updates 用该预测计算误差并入库 (exp/exp_hmem.py:292-338)；V1 存的是最终
        预测。
      - 安全性：输入/预测/损失检测 NaN/Inf，异常时跳过并重置 SNMA (exp/exp_hmem.py:209-248)；V1 未列出这类守卫。
      - 记忆释放：每步训练后强制 snma.reset() 以断开计算图 (exp/exp_hmem.py:178-292 注释处)，实践中避免重复 backward 报错。
      - 预热与校准：测试前新增 update_valid，用验证集预热 SNMA/填充记忆库，并实时打印记忆占用 (exp/exp_hmem.py:342-397)，V1 未包含。
      - 优化器/调度：分组学习率同 V1，但现在可选余弦调度、打印运行 MSE/记忆占用 (exp/exp_hmem.py:469-546)。
      - 适配增益正则：V1 在 _update_online 里有“适配变差时加罚” (H-memV1.md:1873-1882)，当前实现已移除，loss 仅为主 MSE (exp/exp_hmem.py:178-292)。

  可见的新增/缺失点速查

  - 新增：CHRC 校正限幅与全局缩放、AdaptiveCHRC、B 生成器零初始化、验证集预热、NaN 防护、Conv1d/Embedding LoRA 支持。
  - 缺失/更改：SNMA 记忆更新公式被平滑+投影；记忆库入库改为“无校正预测”；适配增益正则已删除；V1 未提到的 chrc_max_correction/memory_num_heads/target_modules 等新超参需
    要在配置中显式设置。