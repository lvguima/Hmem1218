# ACLã€MIRã€CLS-ER æ–¹æ³•è¿ç§»æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [è¿ç§»å‰å‡†å¤‡](#è¿ç§»å‰å‡†å¤‡)
3. [æ–‡ä»¶æ¸…å•](#æ–‡ä»¶æ¸…å•)
4. [è¯¦ç»†è¿ç§»æ­¥éª¤](#è¯¦ç»†è¿ç§»æ­¥éª¤)
5. [ä¾èµ–å…³ç³»è¯´æ˜](#ä¾èµ–å…³ç³»è¯´æ˜)
6. [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
7. [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯)
8. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## æ¦‚è¿°

æœ¬æŒ‡å—ç”¨äºå°†ä»¥ä¸‹ä¸‰ä¸ªæŒç»­å­¦ä¹ æ–¹æ³•ä»å½“å‰ä»£ç åº“è¿ç§»åˆ°å¦ä¸€ä¸ªç›¸åŒæ¶æ„çš„å®éªŒä»£ç åº“ï¼š

- **ACL (Adaptive Continual Learning)**: ä½¿ç”¨è®°å¿†å›æ”¾ã€ç‰¹å¾ä¸€è‡´æ€§å’ŒHintè’¸é¦
- **CLS-ER (Complementary Learning System - Experience Replay)**: ä½¿ç”¨åŒEMAæ¨¡å‹å’Œç½®ä¿¡åº¦é€‰æ‹©
- **MIR (Maximally Interfered Retrieval)**: åŸºäºæ¢¯åº¦å¹²æ‰°çš„æ™ºèƒ½é‡‡æ ·ç­–ç•¥

### æ–¹æ³•ç‰¹ç‚¹å¯¹æ¯”

| æ–¹æ³• | æ ¸å¿ƒåˆ›æ–° | ç¼“å†²åŒºç±»å‹ | é¢å¤–æ¨¡å‹ | è®¡ç®—å¼€é”€ |
|------|---------|-----------|---------|---------|
| **ACL** | åŒç¼“å†²+ç‰¹å¾è’¸é¦ | ReservoirBuffer + SoftBuffer | 1ä¸ªæ•™å¸ˆæ¨¡å‹ | ä¸­ç­‰ |
| **CLS-ER** | åŒEMA+ç½®ä¿¡åº¦é€‰æ‹© | CLSER_Buffer | 2ä¸ªEMAæ¨¡å‹ | ä¸­ç­‰ |
| **MIR** | æœ€å¤§å¹²æ‰°é‡‡æ · | MIR_Buffer | è™šæ‹Ÿæ¨¡å‹ï¼ˆä¸´æ—¶ï¼‰ | è¾ƒé«˜ |

---

## è¿ç§»å‰å‡†å¤‡

### 1. ç¡®è®¤ç›®æ ‡ä»£ç åº“æ¶æ„

ç¡®ä¿ç›®æ ‡ä»£ç åº“å…·æœ‰ä»¥ä¸‹ç»“æ„ï¼š

```
TargetProject/
â”œâ”€â”€ exp/
â”‚   â”œâ”€â”€ exp_basic.py       # åŸºç¡€å®éªŒç±»
â”‚   â”œâ”€â”€ exp_main.py        # ä¸»å®éªŒç±»
â”‚   â””â”€â”€ exp_online.py      # åœ¨çº¿å­¦ä¹ å®éªŒç±»ï¼ˆéœ€è¦å­˜åœ¨æˆ–åˆ›å»ºï¼‰
â”œâ”€â”€ util/
â”‚   â”œâ”€â”€ buffer.py          # åŸºç¡€Bufferç±»ï¼ˆå¯é€‰ï¼Œä¼šè¢«ACL/MIR/CLSERç‹¬ç«‹ä½¿ç”¨ï¼‰
â”‚   â””â”€â”€ metrics.py         # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ models/                # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ data_provider/         # æ•°æ®åŠ è½½å™¨
â””â”€â”€ run.py                 # ä¸»è¿è¡Œè„šæœ¬
```

---

## æ–‡ä»¶æ¸…å•

### å¿…é¡»è¿ç§»çš„æ–‡ä»¶

#### 1. å®éªŒç±»æ–‡ä»¶ï¼ˆæ ¸å¿ƒï¼‰
- **æºæ–‡ä»¶**: `exp/exp_online.py`
- **éœ€è¦è¿ç§»çš„éƒ¨åˆ†**:
  - `Exp_ACL` ç±» (L532-708)
  - `Exp_CLSER` ç±» (L710-816)
  - `Exp_MIR` ç±» (L818-939)

#### 2. å·¥å…·ç±»æ–‡ä»¶
| æ–‡ä»¶ | åŠŸèƒ½ | è¡Œæ•° | ä¾èµ– |
|------|------|------|------|
| `util/acl_utils.py` | ACLä¸“ç”¨å·¥å…·ï¼ˆReservoirBuffer, SoftBufferï¼‰ | 190 | torch, numpy, random |
| `util/clser_utils.py` | CLS-ERä¸“ç”¨å·¥å…·ï¼ˆCLSER_Manager, CLSER_Bufferï¼‰ | 257 | torch, copy.deepcopy |
| `util/mir_utils.py` | MIRä¸“ç”¨å·¥å…·ï¼ˆMIR_Sampler, MIR_Bufferï¼‰ | 335 | torch, numpy, copy.deepcopy |

### å¯é€‰å‚è€ƒæ–‡ä»¶ï¼ˆä¸éœ€è¦è¿ç§»ï¼‰
- `ACL/` - åŸå§‹å‚è€ƒå®ç°
- `test_integration.py` - é›†æˆæµ‹è¯•è„šæœ¬ï¼ˆå¯å‚è€ƒï¼‰
- `scripts/online/test_acl_methods.sh` - æµ‹è¯•è„šæœ¬ï¼ˆå¯å‚è€ƒï¼‰

---

## è¯¦ç»†è¿ç§»æ­¥éª¤

### Step 1: è¿ç§»å·¥å…·ç±»æ–‡ä»¶

#### 1.1 åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„

```bash
cd /path/to/TargetProject
mkdir -p util
```

#### 1.2 å¤åˆ¶å·¥å…·ç±»æ–‡ä»¶

```bash
# å¤åˆ¶ä¸‰ä¸ªå·¥å…·ç±»æ–‡ä»¶
cp /path/to/OnlineTSF/util/acl_utils.py ./util/
cp /path/to/OnlineTSF/util/clser_utils.py ./util/
cp /path/to/OnlineTSF/util/mir_utils.py ./util/
```

#### 1.3 éªŒè¯å·¥å…·ç±»æ–‡ä»¶

ç¡®ä¿æ¯ä¸ªæ–‡ä»¶å¼€å¤´çš„å¯¼å…¥è¯­å¥åœ¨ç›®æ ‡ç¯å¢ƒä¸­å¯ç”¨ï¼š

**acl_utils.py** å¤´éƒ¨å¯¼å…¥ï¼š
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
```

**clser_utils.py** å¤´éƒ¨å¯¼å…¥ï¼š
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from copy import deepcopy
```

**mir_utils.py** å¤´éƒ¨å¯¼å…¥ï¼š
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from copy import deepcopy
import numpy as np
```

---

### Step 2: è¿ç§»å®éªŒç±»

#### 2.1 æ£€æŸ¥ç›®æ ‡ä»£ç åº“çš„ exp_online.py

ç¡®è®¤ç›®æ ‡ä»£ç åº“ä¸­æ˜¯å¦å­˜åœ¨ `exp/exp_online.py`ï¼š

**å¦‚æœå­˜åœ¨**ï¼šè·³åˆ° Step 2.2

**å¦‚æœä¸å­˜åœ¨**ï¼š
1. ä»æºä»£ç åº“å¤åˆ¶åŸºç¡€çš„ `Exp_Online` ç±»
2. æˆ–è€…åˆ›å»ºä¸€ä¸ªç»§æ‰¿è‡ª `Exp_Main` çš„åŸºç±»

ç¤ºä¾‹åŸºç¡€ `Exp_Online` ç±»ï¼š
```python
from exp.exp_main import Exp_Main

class Exp_Online(Exp_Main):
    def __init__(self, args):
        super().__init__(args)
        self.online_phases = ['test', 'online']

    def online(self, online_data=None, target_variate=None, phase='test', show_progress=False):
        # åŸºç¡€åœ¨çº¿å­¦ä¹ é€»è¾‘
        pass

    def _update_online(self, batch, criterion, optimizer, scaler=None):
        # åŸºç¡€åœ¨çº¿æ›´æ–°é€»è¾‘
        pass
```

#### 2.2 æ·»åŠ ä¸‰ä¸ªå®éªŒç±»åˆ° exp_online.py

åœ¨ `exp/exp_online.py` æ–‡ä»¶æœ«å°¾æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š

##### 2.2.1 æ·»åŠ  ACL ç±»

```python
# ============================================================================
# ACL (Adaptive Continual Learning) Methods
# ============================================================================

class Exp_ACL(Exp_Online):
    """
    ACL (Adaptive Continual Learning) Method

    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. Memory Replay: ä»é•¿æœŸè®°å¿†ç¼“å†²åŒºé‡æ”¾æ ·æœ¬
    2. Feature Consistency: ä¿æŒç¼–ç å™¨ç‰¹å¾çš„ä¸€è‡´æ€§
    3. Hint Distillation: é€šè¿‡æ•™å¸ˆæ¨¡å‹ä¼ é€’çŸ¥è¯†

    è®ºæ–‡: "Adaptive Continual Learning for Time Series Forecasting"
    """
    def __init__(self, args):
        super().__init__(args)

        # ACL è¶…å‚æ•°
        self.buffer_size = getattr(args, 'acl_buffer_size', 500)
        self.soft_buffer_size = getattr(args, 'acl_soft_buffer_size', 50)
        self.alpha = getattr(args, 'acl_alpha', 0.2)
        self.beta = getattr(args, 'acl_beta', 0.2)
        self.gamma = getattr(args, 'acl_gamma', 0.2)
        self.task_interval = getattr(args, 'acl_task_interval', 200)

        print(f"[ACL] Initialized with buffer_size={self.buffer_size}, "
              f"alpha={self.alpha}, beta={self.beta}, gamma={self.gamma}")

    # ... [å¤åˆ¶å®Œæ•´çš„ Exp_ACL å®ç°ï¼Œè§æºæ–‡ä»¶ L532-708] ...
```

**å®Œæ•´ä»£ç **ï¼šä»æºæ–‡ä»¶ `exp/exp_online.py` çš„ **L532-708** å¤åˆ¶å…¨éƒ¨ä»£ç ã€‚

##### 2.2.2 æ·»åŠ  CLS-ER ç±»

```python
class Exp_CLSER(Exp_Online):
    """
    CLS-ER (Complementary Learning System - Experience Replay)

    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. åŒEMAæ¨¡å‹ï¼šPlastic Model (å¿«é€Ÿå­¦ä¹ ) + Stable Model (ç¨³å®šå­¦ä¹ )
    2. ç½®ä¿¡åº¦é€‰æ‹©ï¼šæ ¹æ®é¢„æµ‹è¯¯å·®åŠ¨æ€é€‰æ‹©æ•™å¸ˆæ¨¡å‹
    3. ä¸€è‡´æ€§æ­£åˆ™ï¼šå­¦ç”Ÿæ¨¡å‹ä¸é€‰ä¸­çš„æ•™å¸ˆä¿æŒä¸€è‡´

    è®ºæ–‡: "Learning Fast, Learning Slow: A General Continual Learning Method
           based on Complementary Learning System" (ICLR 2022)
    """
    def __init__(self, args):
        super().__init__(args)

        # CLS-ER è¶…å‚æ•°
        self.buffer_size = getattr(args, 'clser_buffer_size', 500)
        self.reg_weight = getattr(args, 'clser_reg_weight', 0.15)

        print(f"[CLS-ER] Initialized with buffer_size={self.buffer_size}, "
              f"reg_weight={self.reg_weight}")

    # ... [å¤åˆ¶å®Œæ•´çš„ Exp_CLSER å®ç°ï¼Œè§æºæ–‡ä»¶ L710-816] ...
```

**å®Œæ•´ä»£ç **ï¼šä»æºæ–‡ä»¶ `exp/exp_online.py` çš„ **L710-816** å¤åˆ¶å…¨éƒ¨ä»£ç ã€‚

##### 2.2.3 æ·»åŠ  MIR ç±»

```python
class Exp_MIR(Exp_Online):
    """
    MIR (Maximally Interfered Retrieval)

    æ ¸å¿ƒåˆ›æ–°ï¼š
    - ä¸æ˜¯éšæœºé‡‡æ ·bufferæ ·æœ¬ï¼Œè€Œæ˜¯é€‰æ‹©å—å½“å‰æ¢¯åº¦æ›´æ–°è´Ÿé¢å½±å“æœ€å¤§çš„æ ·æœ¬
    - é€šè¿‡è™šæ‹Ÿå‚æ•°æ›´æ–°è®¡ç®—å¹²æ‰°åˆ†æ•°
    - é€‰æ‹©top-Kæœ€å¤§å¹²æ‰°æ ·æœ¬è¿›è¡Œå›æ”¾

    è®ºæ–‡: "Online Continual Learning with Maximal Interfered Retrieval" (NeurIPS 2019)
    """
    def __init__(self, args):
        super().__init__(args)

        # MIR è¶…å‚æ•°
        self.buffer_size = getattr(args, 'mir_buffer_size', 500)
        self.mir_subsample = getattr(args, 'mir_subsample', 500)
        self.mir_k = getattr(args, 'mir_k', 50)

        print(f"[MIR] Initialized with buffer_size={self.buffer_size}, "
              f"subsample={self.mir_subsample}, k={self.mir_k}")

    # ... [å¤åˆ¶å®Œæ•´çš„ Exp_MIR å®ç°ï¼Œè§æºæ–‡ä»¶ L818-939] ...
```

**å®Œæ•´ä»£ç **ï¼šä»æºæ–‡ä»¶ `exp/exp_online.py` çš„ **L818-939** å¤åˆ¶å…¨éƒ¨ä»£ç ã€‚

#### 2.3 æ·»åŠ å¿…è¦çš„å¯¼å…¥è¯­å¥

åœ¨ `exp/exp_online.py` æ–‡ä»¶å¼€å¤´æ·»åŠ ï¼š

```python
import copy
import torch
import torch.nn.functional as F
from torch import optim, nn
```

---

### Step 3: ä¿®æ”¹ä¸»è¿è¡Œè„šæœ¬

#### 3.1 æ›´æ–° run.py ä¸­çš„å®éªŒç±»æ˜ å°„

æ‰¾åˆ° `run.py` ä¸­å®šä¹‰å®éªŒç±»çš„éƒ¨åˆ†ï¼Œæ·»åŠ ä¸‰ä¸ªæ–°æ–¹æ³•ï¼š

```python
# åœ¨ run.py ä¸­æ‰¾åˆ°ç±»ä¼¼è¿™æ ·çš„ä»£ç ï¼š
if args.online_method == 'ER':
    Exp = Exp_ER
elif args.online_method == 'DER++':
    Exp = Exp_DERpp
# ... å…¶ä»–æ–¹æ³• ...

# æ·»åŠ ä»¥ä¸‹ä¸‰è¡Œï¼š
elif args.online_method == 'ACL':
    Exp = Exp_ACL
elif args.online_method == 'CLSER':
    Exp = Exp_CLSER
elif args.online_method == 'MIR':
    Exp = Exp_MIR
```

æˆ–è€…ä½¿ç”¨æ›´ç®€æ´çš„æ˜ å°„æ–¹å¼ï¼š

```python
from exp.exp_online import Exp_Online, Exp_ACL, Exp_CLSER, Exp_MIR

METHOD_MAP = {
    'online': Exp_Online,
    'ACL': Exp_ACL,
    'CLSER': Exp_CLSER,
    'MIR': Exp_MIR,
    # ... å…¶ä»–æ–¹æ³• ...
}

Exp = METHOD_MAP.get(args.online_method, Exp_Online)
```

#### 3.2 æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚æœä½¿ç”¨ argparseï¼‰

åœ¨ `run.py` æˆ–å•ç‹¬çš„å‚æ•°é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```python
# ACL å‚æ•°
parser.add_argument('--acl_buffer_size', type=int, default=500)
parser.add_argument('--acl_soft_buffer_size', type=int, default=50)
parser.add_argument('--acl_alpha', type=float, default=0.2, help='Memory replay weight')
parser.add_argument('--acl_beta', type=float, default=0.2, help='Feature consistency weight')
parser.add_argument('--acl_gamma', type=float, default=0.2, help='Hint distillation weight')
parser.add_argument('--acl_task_interval', type=int, default=200, help='Teacher update interval')

# CLS-ER å‚æ•°
parser.add_argument('--clser_buffer_size', type=int, default=500)
parser.add_argument('--clser_reg_weight', type=float, default=0.15, help='Consistency regularization weight')
parser.add_argument('--clser_plastic_update_freq', type=float, default=0.9)
parser.add_argument('--clser_plastic_alpha', type=float, default=0.999)
parser.add_argument('--clser_stable_update_freq', type=float, default=0.7)
parser.add_argument('--clser_stable_alpha', type=float, default=0.999)

# MIR å‚æ•°
parser.add_argument('--mir_buffer_size', type=int, default=500)
parser.add_argument('--mir_subsample', type=int, default=500, help='Subsample size for MIR')
parser.add_argument('--mir_k', type=int, default=50, help='Top-K interfered samples')
```

---

## ä¾èµ–å…³ç³»è¯´æ˜

### ç±»ç»§æ‰¿å…³ç³»

```
Exp_Basic (exp/exp_basic.py)
    â†“
Exp_Main (exp/exp_main.py)
    â†“
Exp_Online (exp/exp_online.py)
    â†“
    â”œâ”€â”€ Exp_ACL
    â”œâ”€â”€ Exp_CLSER
    â””â”€â”€ Exp_MIR
```

### æ–¹æ³•ä¾èµ–çš„çˆ¶ç±»æ¥å£

ä¸‰ä¸ªæ–¹æ³•éƒ½ä¾èµ– `Exp_Online` æä¾›ä»¥ä¸‹æ¥å£ï¼š

| æ–¹æ³•/å±æ€§ | ç”¨é€” | å¿…é¡»å­˜åœ¨ |
|----------|------|---------|
| `self.model` | ä¸»æ¨¡å‹ | âœ… |
| `self.device` | è®¡ç®—è®¾å¤‡ | âœ… |
| `self.args` | è¶…å‚æ•°é…ç½® | âœ… |
| `self._select_optimizer()` | åˆ›å»ºä¼˜åŒ–å™¨ | âœ… |
| `self._select_criterion()` | åˆ›å»ºæŸå¤±å‡½æ•° | âœ… |
| `self.forward(batch)` | å‰å‘ä¼ æ’­ | âœ… |
| `super().online(...)` | çˆ¶ç±»åœ¨çº¿å­¦ä¹ é€»è¾‘ | âœ… |

### å…³é”®å‡è®¾

1. **æ¨¡å‹è¾“å‡ºæ ¼å¼**ï¼š
   - æ”¯æŒ `outputs` æˆ– `(outputs, encoder_features)` ä¸¤ç§æ ¼å¼
   - ACL éœ€è¦ç¼–ç å™¨ç‰¹å¾ç”¨äº Hint Loss

2. **æ‰¹æ¬¡æ•°æ®æ ¼å¼**ï¼š
   ```python
   batch = [batch_x, batch_y, batch_x_mark, batch_y_mark]
   # batch_x: [B, seq_len, enc_in]
   # batch_y: [B, pred_len, c_out]
   ```

3. **æŸå¤±å‡½æ•°**ï¼š
   - é»˜è®¤ä¸º MSELoss
   - æ”¯æŒè‡ªå®šä¹‰ criterion

---

## é…ç½®å‚æ•°

### ACL æ¨èé…ç½®

| å‚æ•° | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|-------|---------|------|
| `acl_buffer_size` | 500 | 200-1000 | é•¿æœŸè®°å¿†å®¹é‡ |
| `acl_soft_buffer_size` | 50 | 20-100 | çŸ­æœŸè®°å¿†å®¹é‡ |
| `acl_alpha` | 0.2 | 0.1-0.5 | Memory replayæƒé‡ |
| `acl_beta` | 0.2 | 0.1-0.5 | Feature consistencyæƒé‡ |
| `acl_gamma` | 0.2 | 0.1-0.5 | Hint distillationæƒé‡ |
| `acl_task_interval` | 200 | 100-500 | æ•™å¸ˆæ¨¡å‹æ›´æ–°é—´éš” |

**æ¨èç»„åˆ**ï¼š
- å°æ•°æ®é›†ï¼ˆ<10Kæ ·æœ¬ï¼‰ï¼š`buffer_size=200, alpha=0.1, beta=0.1, gamma=0.1`
- ä¸­æ•°æ®é›†ï¼ˆ10K-100Kï¼‰ï¼šé»˜è®¤å‚æ•°
- å¤§æ•°æ®é›†ï¼ˆ>100Kï¼‰ï¼š`buffer_size=1000, alpha=0.3, beta=0.3, gamma=0.3`

### CLS-ER æ¨èé…ç½®

| å‚æ•° | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|-------|---------|------|
| `clser_buffer_size` | 500 | 200-1000 | ç¼“å†²åŒºå®¹é‡ |
| `clser_reg_weight` | 0.15 | 0.1-0.3 | ä¸€è‡´æ€§æ­£åˆ™æƒé‡ |
| `clser_plastic_update_freq` | 0.9 | 0.7-0.95 | Plasticæ¨¡å‹æ›´æ–°é¢‘ç‡ |
| `clser_plastic_alpha` | 0.999 | 0.99-0.9999 | Plastic EMAç³»æ•° |
| `clser_stable_update_freq` | 0.7 | 0.5-0.9 | Stableæ¨¡å‹æ›´æ–°é¢‘ç‡ |
| `clser_stable_alpha` | 0.999 | 0.99-0.9999 | Stable EMAç³»æ•° |

**å…³é”®åŸåˆ™**ï¼š
- `plastic_alpha < stable_alpha`ï¼ˆPlasticæ›´æ–°æ›´å¿«ï¼‰
- `plastic_update_freq > stable_update_freq`ï¼ˆPlasticæ›´æ–°æ›´é¢‘ç¹ï¼‰

### MIR æ¨èé…ç½®

| å‚æ•° | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|-------|---------|------|
| `mir_buffer_size` | 500 | 200-1000 | ç¼“å†²åŒºå®¹é‡ |
| `mir_subsample` | 500 | buffer_sizeçš„50%-100% | MIRå€™é€‰æ ·æœ¬æ•° |
| `mir_k` | 50 | 10-100 | Top-Kå¹²æ‰°æ ·æœ¬æ•° |

**æ€§èƒ½æƒè¡¡**ï¼š
- `mir_subsample` è¶Šå¤§ï¼Œé€‰æ‹©è¶Šå‡†ç¡®ï¼Œä½†è®¡ç®—å¼€é”€è¶Šå¤§
- å»ºè®® `mir_k â‰ˆ batch_size / 2`

---

## æµ‹è¯•éªŒè¯

### Step 1: å•å…ƒæµ‹è¯•å·¥å…·ç±»

åˆ›å»º `test_utils.py`ï¼š

```python
import torch
from util.acl_utils import ReservoirBuffer, SoftBuffer
from util.clser_utils import CLSER_Manager, CLSER_Buffer
from util.mir_utils import MIR_Buffer

def test_acl_buffers():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æµ‹è¯• ReservoirBuffer
    rb = ReservoirBuffer(capacity=100, device=device)
    x = torch.randn(8, 96, 7)
    y = torch.randn(8, 96, 7)
    z = torch.randn(8, 96, 64)
    rb.update(x, y, z)

    sampled = rb.sample(batch_size=4)
    assert sampled is not None
    print("âœ… ReservoirBuffer test passed")

    # æµ‹è¯• SoftBuffer
    sb = SoftBuffer(capacity=20, device=device)
    losses = torch.rand(8)
    sb.update(x, y, z, losses)
    data = sb.get_data()
    assert data is not None
    print("âœ… SoftBuffer test passed")

def test_clser():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æµ‹è¯• CLSER_Buffer
    buffer = CLSER_Buffer(capacity=100, device=device)
    x = torch.randn(8, 96, 7)
    y = torch.randn(8, 96, 7)
    buffer.update(x, y)

    sampled_x, sampled_y, _ = buffer.sample(batch_size=4)
    assert sampled_x is not None
    print("âœ… CLSER_Buffer test passed")

def test_mir():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # åˆ›å»ºç®€å•çš„ args
    class Args:
        mir_subsample = 50
        mir_k = 10
        learning_rate = 0.001

    args = Args()

    # æµ‹è¯• MIR_Buffer
    buffer = MIR_Buffer(buffer_size=100, device=device, args=args)
    x = torch.randn(8, 96, 7)
    y = torch.randn(8, 96, 7)
    buffer.add_data(x, y)

    sampled = buffer.get_data(batch_size=4)
    assert sampled is not None
    print("âœ… MIR_Buffer test passed")

if __name__ == '__main__':
    test_acl_buffers()
    test_clser()
    test_mir()
    print("\nğŸ‰ All utility tests passed!")
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
cd /path/to/TargetProject
python test_utils.py
```

### Step 2: é›†æˆæµ‹è¯•

åˆ›å»º `test_methods.sh`ï¼š

```bash
#!/bin/bash

# æµ‹è¯• ACL
echo "Testing ACL..."
python run.py \
  --task_name long_term_forecast \
  --model DLinear \
  --data ETTh1 \
  --online_method ACL \
  --seq_len 96 \
  --pred_len 96 \
  --acl_buffer_size 100 \
  --train_epochs 1

# æµ‹è¯• CLS-ER
echo "Testing CLS-ER..."
python run.py \
  --task_name long_term_forecast \
  --model DLinear \
  --data ETTh1 \
  --online_method CLSER \
  --seq_len 96 \
  --pred_len 96 \
  --clser_buffer_size 100 \
  --train_epochs 1

# æµ‹è¯• MIR
echo "Testing MIR..."
python run.py \
  --task_name long_term_forecast \
  --model DLinear \
  --data ETTh1 \
  --online_method MIR \
  --seq_len 96 \
  --pred_len 96 \
  --mir_buffer_size 100 \
  --train_epochs 1

echo "âœ… All integration tests completed!"
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
chmod +x test_methods.sh
./test_methods.sh
```

### Step 3: æ€§èƒ½å¯¹æ¯”æµ‹è¯•

åˆ›å»ºå¯¹æ¯”æµ‹è¯•è„šæœ¬ï¼š

```bash
#!/bin/bash

METHODS=("online" "ACL" "CLSER" "MIR")
RESULTS_DIR="./results_comparison"
mkdir -p $RESULTS_DIR

for method in "${METHODS[@]}"; do
    echo "Running $method..."
    python run.py \
        --online_method $method \
        --data ETTh1 \
        --seq_len 96 \
        --pred_len 96 \
        --train_epochs 5 \
        > ${RESULTS_DIR}/${method}_output.log 2>&1

    echo "$method completed. Results saved to ${RESULTS_DIR}/${method}_output.log"
done

echo "All methods completed. Compare results in $RESULTS_DIR/"
```

---

## å¸¸è§é—®é¢˜

### Q1: è¿ç§»åæŠ¥é”™ `ModuleNotFoundError: No module named 'util.acl_utils'`

**åŸå› **: å·¥å…·ç±»æ–‡ä»¶æœªæ­£ç¡®å¤åˆ¶æˆ–è·¯å¾„ä¸å¯¹

**è§£å†³**:
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la util/acl_utils.py
ls -la util/clser_utils.py
ls -la util/mir_utils.py

# ç¡®ä¿ util/ æ˜¯ Python åŒ…
touch util/__init__.py
```

### Q2: æŠ¥é”™ `AttributeError: 'Namespace' object has no attribute 'acl_buffer_size'`

**åŸå› **: å‚æ•°æœªåœ¨å‘½ä»¤è¡Œæˆ–é…ç½®æ–‡ä»¶ä¸­å®šä¹‰

**è§£å†³**:
1. æ£€æŸ¥ `run.py` ä¸­æ˜¯å¦æ·»åŠ äº†å‚æ•°å®šä¹‰
2. æˆ–è€…åœ¨è°ƒç”¨æ—¶æ˜¾å¼ä¼ é€’å‚æ•°ï¼š
```bash
python run.py --online_method ACL --acl_buffer_size 500
```

### Q3: ACL æŠ¥é”™ `RuntimeError: encoder output is None`

**åŸå› **: æ¨¡å‹ä¸è¿”å›ç¼–ç å™¨ç‰¹å¾ï¼ŒACLéœ€è¦encoderè¾“å‡ºç”¨äºHint Loss

**è§£å†³**:
- **æ–¹æ¡ˆ1**: ä¿®æ”¹æ¨¡å‹ä½¿å…¶è¿”å› `(output, encoder_features)`
- **æ–¹æ¡ˆ2**: åœ¨ `Exp_ACL._update_online()` ä¸­æ·»åŠ æ£€æŸ¥ï¼š
```python
if enc_out is None:
    # è·³è¿‡ Hint Loss
    loss_hint = torch.tensor(0.0, device=self.device)
```

### Q4: CLS-ER æ˜¾å­˜å ç”¨è¿‡å¤§

**åŸå› **: åŒEMAæ¨¡å‹å ç”¨é¢å¤–æ˜¾å­˜

**è§£å†³**:
1. å‡å° `clser_buffer_size`
2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š`--use_amp`
3. å‡å°æ¨¡å‹å°ºå¯¸

### Q5: MIR è¿è¡Œé€Ÿåº¦å¾ˆæ…¢

**åŸå› **: MIRéœ€è¦é¢å¤–çš„è™šæ‹Ÿæ¨¡å‹å‰å‘ä¼ æ’­è®¡ç®—å¹²æ‰°åˆ†æ•°

**è§£å†³**:
1. å‡å° `mir_subsample`ï¼ˆå‡å°‘å€™é€‰æ ·æœ¬ï¼‰
2. å‡å° `mir_k`ï¼ˆå‡å°‘é€‰æ‹©æ ·æœ¬ï¼‰
3. å¢å¤§ `batch_size`ï¼ˆæ‘Šé”€è®¡ç®—å¼€é”€ï¼‰

### Q6: ä¸‰ä¸ªæ–¹æ³•çš„æ•ˆæœä¸å¦‚é¢„æœŸ

**åŸå› **: è¶…å‚æ•°æœªè°ƒä¼˜

**è§£å†³**:
å‚è€ƒ [é…ç½®å‚æ•°](#é…ç½®å‚æ•°) ç« èŠ‚ï¼Œæ ¹æ®æ•°æ®é›†ç‰¹æ€§è°ƒæ•´ï¼š
- å°æ•°æ®é›†ï¼šå‡å°bufferå¤§å°å’Œæƒé‡
- å¤§æ•°æ®é›†ï¼šå¢å¤§bufferå¤§å°å’Œæƒé‡
- æ•°æ®åˆ†å¸ƒå˜åŒ–å¿«ï¼šå¢å¤§ `task_interval`ï¼ˆACLï¼‰æˆ–æ›´æ–°é¢‘ç‡ï¼ˆCLS-ERï¼‰

### Q7: å¦‚ä½•ä¸ç°æœ‰çš„åœ¨çº¿å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ER, DER++ï¼‰å¯¹æ¯”ï¼Ÿ

**ç­”**: åœ¨ç›¸åŒé…ç½®ä¸‹è¿è¡Œï¼š

```bash
# Baseline: æ ‡å‡†åœ¨çº¿å­¦ä¹ 
python run.py --online_method online --data ETTh1

# ER (Experience Replay)
python run.py --online_method ER --data ETTh1

# ACL
python run.py --online_method ACL --data ETTh1

# CLS-ER
python run.py --online_method CLSER --data ETTh1

# MIR
python run.py --online_method MIR --data ETTh1
```

---

## é™„å½•ï¼šå®Œæ•´è¿ç§»æ£€æŸ¥æ¸…å•

### âœ… è¿ç§»å‰æ£€æŸ¥
- [ ] ç¡®è®¤ç›®æ ‡ä»£ç åº“æ¶æ„ä¸æºä»£ç åº“å…¼å®¹
- [ ] å¤‡ä»½ç›®æ ‡ä»£ç åº“
- [ ] ç¡®è®¤Pythonç¯å¢ƒå’Œä¾èµ–é¡¹

### âœ… æ–‡ä»¶è¿ç§»
- [ ] å¤åˆ¶ `util/acl_utils.py`
- [ ] å¤åˆ¶ `util/clser_utils.py`
- [ ] å¤åˆ¶ `util/mir_utils.py`
- [ ] åœ¨ `exp/exp_online.py` ä¸­æ·»åŠ  `Exp_ACL` ç±»
- [ ] åœ¨ `exp/exp_online.py` ä¸­æ·»åŠ  `Exp_CLSER` ç±»
- [ ] åœ¨ `exp/exp_online.py` ä¸­æ·»åŠ  `Exp_MIR` ç±»

### âœ… ä»£ç ä¿®æ”¹
- [ ] æ›´æ–° `run.py` ä¸­çš„å®éªŒç±»æ˜ å°„
- [ ] æ·»åŠ å‘½ä»¤è¡Œå‚æ•°å®šä¹‰
- [ ] æ·»åŠ å¿…è¦çš„å¯¼å…¥è¯­å¥

### âœ… æµ‹è¯•éªŒè¯
- [ ] è¿è¡Œå·¥å…·ç±»å•å…ƒæµ‹è¯•
- [ ] è¿è¡ŒACLé›†æˆæµ‹è¯•
- [ ] è¿è¡ŒCLS-ERé›†æˆæµ‹è¯•
- [ ] è¿è¡ŒMIRé›†æˆæµ‹è¯•
- [ ] å¯¹æ¯”ä¸‰ä¸ªæ–¹æ³•ä¸baselineçš„æ€§èƒ½

### âœ… æ–‡æ¡£
- [ ] åœ¨READMEä¸­æ·»åŠ ä¸‰ä¸ªæ–¹æ³•çš„è¯´æ˜
- [ ] æ·»åŠ ç¤ºä¾‹è¿è¡Œå‘½ä»¤
- [ ] è®°å½•è¶…å‚æ•°æ¨èé…ç½®

---

## æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°è¿ç§»é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. **æ—¥å¿—è¾“å‡º**: æŸ¥çœ‹ `[ACL]`, `[CLS-ER]`, `[MIR]` å¼€å¤´çš„æ—¥å¿—
2. **æºä»£ç **: å‚è€ƒ `OnlineTSF/exp/exp_online.py` L532-939
3. **å‚è€ƒå®ç°**: æŸ¥çœ‹ `ACL/` æ–‡ä»¶å¤¹ä¸‹çš„åŸå§‹å®ç°

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2025-01-XX): åˆå§‹ç‰ˆæœ¬
  - æ”¯æŒ ACL, CLS-ER, MIR ä¸‰ä¸ªæ–¹æ³•çš„å®Œæ•´è¿ç§»

---

**ç¥è¿ç§»é¡ºåˆ©ï¼** ğŸš€
